# Final Project
---

PROJECT PROPOSAL
Working in the healthcare industry as a Data Analyst, I am often required to comb through thousands of patient records to write up a report to present to upper management. Currently, our data is in csv format and we handle it using Pandas, which is relatively efficient. However, due to the magnitude of the data it is often the case that the requirements change by the time the report is generated. A smarter method to sift through the data is needed in order to fulfil the requirements in a timely fashion. 
I shall be looking to integrate Dask and Parquet/Apache in order to speed up the lookup process and facilitate the data handling in order to better serve the business as a whole. Processing data in parallel, means less time to execute, less time to wait and more time to analyze. Due to the nature of data, security is also paramount, hence, encryption must also be taken into account. 
The main goals of this project are to:
•	Maximize efficiency when it comes to computational power. 
•	Come up with a framework to transition using Dask at work.
a.	Look at the possibility of setting up a cluster 
•	Compare the time reduction associated with using Dask as opposed to Pandas.
As a consequence of being in the healthcare industry, I shall be unable to share the data used. I will look into the possibility of using fake data to measure the effect of using Dask versus without.  
------

UPDATE: 
After getting feedback from my peers and instructors, I have decided to alter the requirements of this project to incorporate the feedback received. I have decided to focus more on building a pipeline using Luigi and incorporating Dask in order to process the data.  The main objectives of this project are therefore: 
1.	Collect Data 
2.	Clean Up Data 
3.	Merge Billing Data and Fair Health Data 
4.	Build a simple Linear Regression Model 



